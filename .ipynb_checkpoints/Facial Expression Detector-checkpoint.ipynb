{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook details a deep learning approach to image modeling using keras and tensorflow on the backend. Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and productions. TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. Using keras and tensorflow together provides us with a simplified method of developing an image classification model. The general process to building this detector is as follows:\n",
    "\n",
    "1. Obtain labeled data \n",
    "2. Identify the structure of our image data \n",
    "3. Prepare the data for modeling\n",
    "4. Select the appropriate model parameters\n",
    "5. Fit the model \n",
    "6. Validate the model using metrics\n",
    "7. Evaluate predictions \n",
    "\n",
    "Before we begin, we need to load the appropriate libraries needed to run the notenook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Data \n",
    "\n",
    "After loading the libraries, we then need to load the training and testing data. This data was sourced from a kaggle competition located here: https://www.kaggle.com/c/emotion-detection-from-facial-expressions/overview. The raw data can be found here: https://github.com/muxspace/facial_expressions. Due to the size limitations of github, the images will have to be stored in a separate location not contained in this repository. To run this notebook we will need to specify the directory of the images folder and the path to the csv file containing the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data (mac/unix) locations\n",
    "# IMAGES = \"/Users/chad/Projects/large-data-files/Emotion-Detecion/images\" # Folder containing images\n",
    "# LABELS = '/Users/chad/Projects/large-data-files/Emotion-Detecion/data/legend.csv' # CSV with image file names and correct labels\n",
    "\n",
    "# Specify data (Windows) locations\n",
    "IMAGES = r'C:\\Users\\chad\\Projects\\Large-Data-Files\\Emotion-Detecion\\images' # Folder containing images\n",
    "LABELS = r'C:\\Users\\chad\\Projects\\Large-Data-Files\\Emotion-Detecion\\data\\legend.csv' # CSV with image file names and correct labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the structure of our image data\n",
    "\n",
    "The data is provided in two forms. First, there is a folder of the raw images to be processed. The second is a .csv file containing image labels for each file name in the images folder. In order to build this model, we need to load the images and append the appropriate labels to the data. Before we load the data, we want to know how we should format the height x width image data dimensions for inputting to a keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to know how we should format the height x width image data dimensions\n",
    "# for inputting to a keras model\n",
    "def get_size_statistics():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(IMAGES):\n",
    "        try:\n",
    "            path = os.path.join(IMAGES, img)\n",
    "            if \"DS_Store\" not in path:\n",
    "                data = np.array(Image.open(path))\n",
    "                heights.append(data.shape[0])\n",
    "                widths.append(data.shape[1])\n",
    "                img_count += 1\n",
    "        except:\n",
    "            continue\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "\n",
    "get_size_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the analysis show that our average image height is 335 and our average image width is 333. This means that when we fit our model we can select dimensions as high as these values and should not run into any major issues. I have already experimented with several data dimensions and determined that using lower values does not degrade model performance whereas using high values exponentially increased training time. As such, for the purpose of this analysis I will use a 30 x 30 data dimension when loading the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this analysis is contained within one folder. This means that before building the training data, we should set aside a subset of images to evaluate our model predictions after we build the model. The code below first loads the labeled csv file and cleans up the label (converts all strings to lower case for consistency). We then create a new column of integer codes based on this label. This is important as the keras to_categorical function requires an integer value to work. We then take a randomly selected 10% subset of this data frame for later testing. The test records are then removed from the training dataset and we reset the index of both data frames to account for this reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(LABELS)\n",
    "train.emotion = train.emotion.apply(lambda x: x.lower())\n",
    "train.emotion = pd.Categorical(train.emotion)\n",
    "train['code'] = train.emotion.cat.codes\n",
    "test = train.sample(frac=0.1, replace=True, random_state=1) # take 10% of records to make predictions later\n",
    "train = pd.concat([train, test]).drop_duplicates(keep=False).reset_index() # remove test from training set\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the image function from keras preprocessing, we then load the images with the specified dimensions above (30 x 30 x 1) and convert them to an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img(IMAGES+'/'+train['image'][i], target_size=(50,50,1), color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last portion of the data preparation involves us converting the multi class labels into categorical columns that will be used during training and then creating a training set and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_image)\n",
    "y = train['code'].values\n",
    "y = to_categorical(y) # dummie code\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2) # takes 20% of records for y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the appropriate model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a simple architecture with 2 convolutional layers, one dense hidden layer and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(50,50,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the model using metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the model we need to generate predictions on the randomly sampled 10% of images in the data folder. Before we can do this, we need to load and prepare the image data the same way we prepared the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    img = image.load_img(IMAGES+'/'+test['image'][i], target_size=(50,50,1), color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    test_image.append(img)\n",
    "test_data = np.array(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data prepared, we can generate the predictions from the model. We will take these predictions and append them as a new column in the test data frame allowing us to compare the predicted value to the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "test['predicted'] = model.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are in the form of the coded numeric values, these are not very human readable as we can't easily determine which emotion corresponds to what code. In order to remedy this, we will join the appropriate emotion to the corresponding predicted class code. We will also take this time to clean up the data frame by selecting the relevant columns and renaming the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predicted emotion column\n",
    "ids = test[['emotion', 'code']].drop_duplicates() # create df of codes and meotions\n",
    "ids.columns = ['predicted_emotion', 'code'] # rename column names\n",
    "test = pd.merge(test, ids, how='left', left_on='predicted', right_on='code') # join emotions to codes\n",
    "test = test[['user.id', 'image', 'emotion', 'code_x', 'predicted', 'predicted_emotion']] # select relevant columns\n",
    "test.columns =['user.id', 'image', 'emotion', 'emotion_code', 'predicted_code', 'predicted_emotion'] # rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the test data has some predictions, we can calculate the accuracy of the model predictions. The Accuracy metric will be used, in multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test['predicted_code']\n",
    "y_true = test['emotion_code']\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions\n",
    "\n",
    "Our model accurately classified 83.565% of the images, not bad! Let's now look at the actual images, the label, and the predicted label to visually confirm our models performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to print image, true label, and prediction\n",
    "\n",
    "def print_image(index):\n",
    "    img = image.load_img(IMAGES+'/'+test['image'][index], target_size=(300,300,1), color_mode = \"grayscale\")\n",
    "    plt.imshow(img, cmap = 'gist_gray')\n",
    "    print('Model predicted ' + test['predicted_emotion'][index] + ' the true emotion is ' + test['emotion'][index])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(500) # Look at the 500th image in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(10) # look at the 10th image in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(20) # look at the 20th image in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(345) # look at the 345th image in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(88) # look at the 88th image in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look and see how our model distributed it's predictions. This is especially important for data sets with high class imbalances. The graph below shows the distribution of the true labeled emotion images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"emotion\", data=test)\n",
    "labels = ax.get_xticklabels()\n",
    "ax = ax.set_xticklabels(labels, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second graph below shows the distribution of the predicted emotion images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"predicted_emotion\", data=test)\n",
    "labels = ax.get_xticklabels()\n",
    "ax = ax.set_xticklabels(labels, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it seems our model under classified anger, disgust, fear, sadness, and surprise. Tuning the data size and the parameters used in training may improve the classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(10) # look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
